2015-02-05 22:01:23+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:01:23+0200 [urlS] INFO: Spider opened
2015-02-05 22:01:23+0200 [urlS] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-02-05 22:01:23+0200 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-02-05 22:01:23+0200 [scrapy] DEBUG: Web service listening on 127.0.0.1:6080
2015-02-05 22:01:23+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:01:24+0200 [urlS] DEBUG: Crawled (200) <GET http://www.whitegroupmaths.com> (referer: None)
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=email'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=blog'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=twitter'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=facebook'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=pinterest'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/post-edit.g?blogID=1311271570694606879&postID=4852170376606602511&from=pencil'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.whitegroupmaths.com/search?updated-max=2014-12-20T08:03:00-08:00&max-results=1'}
2015-02-05 22:01:24+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.sitesforteaching.com/in.php?id=www.whitegroupmaths.com'}
2015-02-05 22:01:24+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:01:24+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 1, 24, 209471),
	 'item_scraped_count': 8,
	 'log_count/DEBUG': 11,
	 'log_count/INFO': 5,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 1, 23, 326664)}
2015-02-05 22:01:24+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:02:09+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:02:10+0200 [urlS] DEBUG: Crawled (200) <GET http://www.whitegroupmaths.com> (referer: None)
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=email'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=blog'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=twitter'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=facebook'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=pinterest'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/post-edit.g?blogID=1311271570694606879&postID=4852170376606602511&from=pencil'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.whitegroupmaths.com/search?updated-max=2014-12-20T08:03:00-08:00&max-results=1'}
2015-02-05 22:02:10+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.sitesforteaching.com/in.php?id=www.whitegroupmaths.com'}
2015-02-05 22:02:10+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:02:10+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 2, 10, 33848),
	 'item_scraped_count': 8,
	 'log_count/DEBUG': 9,
	 'log_count/INFO': 2,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 2, 9, 342319)}
2015-02-05 22:02:10+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:02:10+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:05:16+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:05:16+0200 [urlS] DEBUG: Crawled (200) <GET http://www.whitegroupmaths.com> (referer: None)
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=email'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=blog'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=twitter'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=facebook'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/share-post.g?blogID=1311271570694606879&postID=4852170376606602511&target=pinterest'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.blogger.com/post-edit.g?blogID=1311271570694606879&postID=4852170376606602511&from=pencil'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.whitegroupmaths.com/search?updated-max=2014-12-20T08:03:00-08:00&max-results=1'}
2015-02-05 22:05:16+0200 [urlS] DEBUG: Scraped from <200 http://www.whitegroupmaths.com>
	{'link': u'http://www.sitesforteaching.com/in.php?id=www.whitegroupmaths.com'}
2015-02-05 22:05:16+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:05:16+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 5, 16, 779711),
	 'item_scraped_count': 8,
	 'log_count/DEBUG': 9,
	 'log_count/INFO': 2,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 5, 16, 88009)}
2015-02-05 22:05:16+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:05:16+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:07:01+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:07:02+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:07:02+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 7, 2, 323949),
	 'item_scraped_count': 8,
	 'log_count/INFO': 2,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 7, 1, 636941)}
2015-02-05 22:07:02+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:07:02+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:09:15+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:09:16+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:09:16+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 9, 16, 175924),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 9, 15, 436012)}
2015-02-05 22:09:16+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:09:16+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:18:53+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:18:59+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:18:59+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 18, 59, 770365),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 18, 53, 194437)}
2015-02-05 22:18:59+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:18:59+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:21:29+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:21:30+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:21:30+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 21, 30, 601401),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 21, 29, 767937)}
2015-02-05 22:21:30+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:21:30+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:22:00+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:22:01+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:22:01+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 22, 1, 476106),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 22, 0, 567743)}
2015-02-05 22:22:01+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:22:01+0200 [scrapy] INFO: ------------>Running stoped
2015-02-05 22:22:19+0200 [scrapy] INFO: ------------>Running reactor
2015-02-05 22:22:20+0200 [urlS] INFO: Closing spider (finished)
2015-02-05 22:22:20+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 5, 20, 22, 20, 726368),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 5, 20, 22, 19, 995403)}
2015-02-05 22:22:20+0200 [urlS] INFO: Spider closed (finished)
2015-02-05 22:22:20+0200 [scrapy] INFO: ------------>Running stoped
2015-02-07 03:57:07+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 03:57:10+0200 [urlS] INFO: Closing spider (finished)
2015-02-07 03:57:10+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 7, 1, 57, 10, 550618),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 7, 1, 57, 7, 580833)}
2015-02-07 03:57:10+0200 [urlS] INFO: Spider closed (finished)
2015-02-07 03:57:10+0200 [scrapy] INFO: ------------>Running stoped
2015-02-07 04:08:43+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 04:08:46+0200 [urlS] INFO: Closing spider (finished)
2015-02-07 04:08:46+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 7, 2, 8, 46, 671175),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 7, 2, 8, 37, 266064)}
2015-02-07 04:08:46+0200 [urlS] INFO: Spider closed (finished)
2015-02-07 04:08:58+0200 [scrapy] INFO: ------------>Running stoped
2015-02-07 04:09:13+0200 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2015-02-07 04:09:13+0200 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-02-07 04:09:13+0200 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-02-07 04:09:13+0200 [scrapy] INFO: Enabled item pipelines: 
2015-02-07 04:09:14+0200 [urlS] INFO: Spider opened
2015-02-07 04:09:14+0200 [urlS] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-02-07 04:09:14+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 04:09:17+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:09:17+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:09:17+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:09:17+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:09:17+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:09:17+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 47, in <module>
2015-02-07 04:09:17+0200 [-] ERROR:     reactor.run()
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1191, in run
2015-02-07 04:09:17+0200 [-] ERROR:     self.startRunning(installSignalHandlers=installSignalHandlers)
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1171, in startRunning
2015-02-07 04:09:17+0200 [-] ERROR:     ReactorBase.startRunning(self)
2015-02-07 04:09:17+0200 [-] ERROR:   File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 683, in startRunning
2015-02-07 04:09:17+0200 [-] ERROR:     raise error.ReactorNotRestartable()
2015-02-07 04:09:17+0200 [-] ERROR: ReactorNotRestartable
2015-02-07 04:09:50+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:09:50+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:09:50+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:09:50+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:09:50+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:09:50+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:09:50+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:09:50+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:09:50+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 32, in <module>
2015-02-07 04:09:50+0200 [-] ERROR:     os.chdir("./urlS")
2015-02-07 04:09:50+0200 [-] ERROR: OSError: [Errno 2] No such file or directory: './urlS'
2015-02-07 04:10:03+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:10:03+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:10:03+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:10:03+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:10:03+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:10:03+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:10:03+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:10:03+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:10:03+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 32, in <module>
2015-02-07 04:10:03+0200 [-] ERROR:     os.chdir("./urlS")
2015-02-07 04:10:03+0200 [-] ERROR: OSError: [Errno 2] No such file or directory: './urlS'
2015-02-07 04:10:08+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:10:08+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:10:08+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:10:08+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:10:08+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:10:08+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:10:08+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:10:08+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:10:08+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 32, in <module>
2015-02-07 04:10:08+0200 [-] ERROR:     os.chdir("./urlS")
2015-02-07 04:10:08+0200 [-] ERROR: OSError: [Errno 2] No such file or directory: './urlS'
2015-02-07 04:10:11+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:10:11+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:10:11+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:10:11+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:10:11+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:10:11+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:10:11+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:10:11+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:10:11+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 32, in <module>
2015-02-07 04:10:11+0200 [-] ERROR:     os.chdir("./urlS")
2015-02-07 04:10:11+0200 [-] ERROR: OSError: [Errno 2] No such file or directory: './urlS'
2015-02-07 04:10:16+0200 [-] ERROR: Traceback (most recent call last):
2015-02-07 04:10:16+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1314, in main
2015-02-07 04:10:16+0200 [-] ERROR:     pdb._runscript(mainpyfile)
2015-02-07 04:10:16+0200 [-] ERROR:   File "/usr/lib/python2.7/pdb.py", line 1233, in _runscript
2015-02-07 04:10:16+0200 [-] ERROR:     self.run(statement)
2015-02-07 04:10:16+0200 [-] ERROR:   File "/usr/lib/python2.7/bdb.py", line 400, in run
2015-02-07 04:10:16+0200 [-] ERROR:     exec cmd in globals, locals
2015-02-07 04:10:16+0200 [-] ERROR:   File "<string>", line 1, in <module>
2015-02-07 04:10:16+0200 [-] ERROR:   File "/home/kostas/AraxniProject/main.py", line 32, in <module>
2015-02-07 04:10:16+0200 [-] ERROR:     os.chdir("./urlS")
2015-02-07 04:10:16+0200 [-] ERROR: OSError: [Errno 2] No such file or directory: './urlS'
2015-02-07 04:12:00+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 04:12:05+0200 [urlS] INFO: Closing spider (finished)
2015-02-07 04:12:05+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 7, 2, 12, 5, 114281),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 7, 2, 12, 0, 644563)}
2015-02-07 04:12:05+0200 [urlS] INFO: Spider closed (finished)
2015-02-07 04:12:05+0200 [scrapy] INFO: ------------>Running stoped
2015-02-07 04:13:04+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 04:13:05+0200 [urlS] INFO: Closing spider (finished)
2015-02-07 04:13:05+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 7, 2, 13, 5, 437622),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 7, 2, 13, 4, 124290)}
2015-02-07 04:13:05+0200 [urlS] INFO: Spider closed (finished)
2015-02-07 04:13:05+0200 [scrapy] INFO: ------------>Running stoped
2015-02-07 04:13:17+0200 [scrapy] INFO: ------------>Running reactor
2015-02-07 04:13:18+0200 [urlS] INFO: Closing spider (finished)
2015-02-07 04:13:18+0200 [urlS] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 222,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 99240,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2015, 2, 7, 2, 13, 18, 970153),
	 'item_scraped_count': 8,
	 'response_received_count': 1,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/memory': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/memory': 1,
	 'start_time': datetime.datetime(2015, 2, 7, 2, 13, 17, 462959)}
2015-02-07 04:13:18+0200 [urlS] INFO: Spider closed (finished)
2015-02-07 04:13:18+0200 [scrapy] INFO: ------------>Running stoped
